# ... (æ—¢å­˜ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨åˆæœŸè¨­å®š) ...
# from discord.ext import commands <- ã“ã‚Œã«åŠ ãˆ
from discord_ext_voice_recv import VoiceRecvClient # æ–°ã—ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# ... (æ—¢å­˜ã®ã‚¯ãƒ©ã‚¹å®šç¾©ã‚„ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°) ...

# VoiceRecvClientã‚’æ‰±ã†ãŸã‚ã®connectionsè¾æ›¸æ›´æ–°
connections: Dict[int, VoiceRecvClient] = {}

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²éŸ³ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã«ç®¡ç†
# ä¾‹: {guild_id: {user_id: [audio_chunks], ...}}
realtime_audio_buffers: Dict[int, Dict[int, bytearray]] = {}
# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®VADçŠ¶æ…‹ã‚’ç®¡ç†
# ä¾‹: {guild_id: {user_id: True/False, ...}}
user_speaking_status: Dict[int, Dict[int, bool]] = {}
# ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç† (å…ƒã®ã‚³ãƒ¼ãƒ‰ã® tempfile ã¯ãã®ã¾ã¾åˆ©ç”¨å¯èƒ½)
# è»¢å†™å‡¦ç†ã®ã‚¿ã‚¹ã‚¯ã‚’ç®¡ç†
transcription_tasks: Dict[int, Dict[int, asyncio.Task]] = {}


class RealtimeVoiceDataProcessor:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨STTå‡¦ç†ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self, output_dir: str, stt_handler: SpeechToTextHandler):
        self.output_dir = output_dir
        self.stt_handler = stt_handler
        self.start_time = int(time.time())

    async def handle_speaking_start(self, guild_id: int, user: discord.Member):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—å§‹ã‚ãŸã¨ãã®å‡¦ç†"""
        print(f"ğŸ¤ {user.display_name} (ID: {user.id}) ãŒè©±ã—å§‹ã‚ã¾ã—ãŸã€‚")
        if guild_id not in realtime_audio_buffers:
            realtime_audio_buffers[guild_id] = {}
        if user.id not in realtime_audio_buffers[guild_id]:
            realtime_audio_buffers[guild_id][user.id] = bytearray()
        user_speaking_status[guild_id][user.id] = True

    async def handle_speaking_stop(self, guild_id: int, user: discord.Member):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—çµ‚ãˆãŸã¨ãã®å‡¦ç†"""
        print(f"ğŸ”‡ {user.display_name} (ID: {user.id}) ãŒè©±ã—çµ‚ãˆã¾ã—ãŸã€‚")
        user_speaking_status[guild_id][user.id] = False

        if guild_id in realtime_audio_buffers and user.id in realtime_audio_buffers[guild_id]:
            pcm_data = bytes(realtime_audio_buffers[guild_id].pop(user.id))
            if pcm_data:
                # éåŒæœŸã‚¿ã‚¹ã‚¯ã¨ã—ã¦éŸ³å£°å‡¦ç†ã‚’å®Ÿè¡Œ
                task = asyncio.create_task(
                    self.process_single_user_audio(
                        pcm_data,
                        user.id,
                        user.display_name,
                        bot.get_channel(connections[guild_id].channel.id) # ã¾ãŸã¯ ctx.channel ã‚’ã©ã“ã‹ã‹ã‚‰æ¸¡ã™
                    )
                )
                if guild_id not in transcription_tasks:
                    transcription_tasks[guild_id] = {}
                transcription_tasks[guild_id][user.id] = task
            else:
                print(f"âš ï¸ {user.display_name} ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã—ãŸã€‚")
        else:
            print(f"âš ï¸ {user.display_name} ã®éŸ³å£°ãƒãƒƒãƒ•ã‚¡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    async def process_single_user_audio(self, pcm_data: bytes, user_id: int, username: str, text_channel: discord.TextChannel):
        """å€‹åˆ¥ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ï¼ˆä¿å­˜ã€è»¢å†™ã€çµæœé€ä¿¡ï¼‰"""
        print(f"--- éŸ³å£°å‡¦ç†é–‹å§‹: {username} ---")
        speaker_info = self.identify_speaker(user_id, username)
        temp_audio_path = await self.save_temp_audio_file(pcm_data, user_id, username)

        transcription = None
        if temp_audio_path:
            transcription = await self.stt_handler.transcribe_with_local_whisper(temp_audio_path)
            try:
                os.remove(temp_audio_path)
                print(f"ğŸ—‘ï¸ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {temp_audio_path}")
            except Exception as e:
                print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {temp_audio_path} - {e}")
        else:
            print(f"âŒ {username} ã®ä¸€æ™‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")

        if transcription and transcription.strip():
            await text_channel.send(f"**{username}**: {transcription}")
            await self.save_transcription(user_id, username, transcription, speaker_info)
        else:
            await text_channel.send(f"**{username}**: _(è»¢å†™å¤±æ•—ã¾ãŸã¯éŸ³å£°ãªã—)_")
            print(f"âŒ {username} ã®éŸ³å£°è»¢å†™ã«å¤±æ•—ã—ã¾ã—ãŸ (ç©ºã¾ãŸã¯None)")
        print(f"--- éŸ³å£°å‡¦ç†å®Œäº†: {username} ---")


    async def save_temp_audio_file(self, pcm_data: bytes, user_id: int, username: str) -> Optional[str]:
        """PCMãƒ‡ãƒ¼ã‚¿ã‚’WAVå½¢å¼ã§ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ (æ—¢å­˜é–¢æ•°ã‚’æµç”¨)"""
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_file:
                temp_path = temp_file.name
            with wave.open(temp_path, 'wb') as wf:
                wf.setnchannels(2)
                wf.setsampwidth(2)
                wf.setframerate(48000)
                wf.writeframes(pcm_data)
            print(f"ğŸ“ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {username} -> {temp_path}")
            return temp_path
        except Exception as e:
            print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼ ({username}): {e}")
            return None

    async def save_transcription(self, user_id: int, username: str, transcription: str, speaker_info: Dict):
        """è»¢å†™çµæœã‚’JSONLå½¢å¼ã§ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ (æ—¢å­˜é–¢æ•°ã‚’æµç”¨)"""
        transcript_file = os.path.join(self.output_dir, f"transcriptions_{self.start_time}.jsonl")
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        transcript_entry = {
            'timestamp': timestamp,
            'user_id': user_id,
            'username': username,
            'transcription': transcription,
            'speaker_info': speaker_info
        }
        try:
            with open(transcript_file, 'a', encoding='utf-8') as f:
                f.write(f"{json.dumps(transcript_entry, ensure_ascii=False)}\n")
            print(f"ğŸ’¾ è»¢å†™çµæœä¿å­˜: {transcript_file}")
        except Exception as e:
            print(f"è»¢å†™çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªéŸ³å£°ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’æ›´æ–°
realtime_voice_processor = RealtimeVoiceDataProcessor(AUDIO_OUTPUT_DIR, SpeechToTextHandler(None))

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—ã¦ã„ã‚‹ã‹ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ¤œçŸ¥ã—ã€éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã™ã‚‹ãƒªã‚¹ãƒŠãƒ¼
@bot.event
async def on_voice_receive(user: discord.Member, chunk: bytes):
    """
    discord-ext-voice-recv ã‹ã‚‰ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å—ä¿¡
    """
    if user.bot: # ãƒœãƒƒãƒˆè‡ªèº«ã®éŸ³å£°ã¯ç„¡è¦–
        return

    guild_id = user.guild.id
    user_id = user.id

    if guild_id in connections and connections[guild_id].is_currently_recording:
        if guild_id not in realtime_audio_buffers:
            realtime_audio_buffers[guild_id] = {}
        if user_id not in realtime_audio_buffers[guild_id]:
            realtime_audio_buffers[guild_id][user_id] = bytearray()
        
        # éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
        realtime_audio_buffers[guild_id][user_id].extend(chunk)

@bot.event
async def on_voice_member_speaking_start(member: discord.Member):
    """ãƒ¡ãƒ³ãƒãƒ¼ãŒè©±ã—å§‹ã‚ãŸã¨ãã«å‘¼ã°ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ"""
    if member.bot:
        return
    guild_id = member.guild.id
    if guild_id in connections and connections[guild_id].is_currently_recording:
        # VADçŠ¶æ…‹ã‚’æ›´æ–°ã—ã€å¿…è¦ãªåˆæœŸåŒ–ã‚’è¡Œã†
        if guild_id not in user_speaking_status:
            user_speaking_status[guild_id] = {}
        await realtime_voice_processor.handle_speaking_start(guild_id, member)

@bot.event
async def on_voice_member_speaking_stop(member: discord.Member):
    """ãƒ¡ãƒ³ãƒãƒ¼ãŒè©±ã—çµ‚ãˆãŸã¨ãã«å‘¼ã°ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ"""
    if member.bot:
        return
    guild_id = member.guild.id
    if guild_id in connections and connections[guild_id].is_currently_recording:
        await realtime_voice_processor.handle_speaking_stop(guild_id, member)


@bot.command()
async def join(ctx):
    """ãƒœãƒƒãƒˆã‚’ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«æ¥ç¶šã—ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°éŒ²éŸ³ãƒ»è»¢å†™ã‚’é–‹å§‹"""
    if ctx.author.voice is None:
        await ctx.send("âŒ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«æ¥ç¶šã—ã¦ãã ã•ã„ã€‚")
        return

    voice_channel = ctx.author.voice.channel
    
    # æ—¢å­˜ã®æ¥ç¶šãŒã‚ã‚Œã°åˆ‡æ–­
    if ctx.guild.id in connections:
        old_vc = connections[ctx.guild.id]
        if hasattr(old_vc, 'is_currently_recording') and old_vc.is_currently_recording:
            # éŒ²éŸ³ä¸­ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã„ã‚Œã°ã€ãã®æ™‚ç‚¹ã¾ã§ã®éŸ³å£°ã‚’å‡¦ç†ã—ã¦åœæ­¢
            for user_id, buffer in realtime_audio_buffers.get(ctx.guild.id, {}).items():
                if buffer: # ãƒãƒƒãƒ•ã‚¡ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°å‡¦ç†
                    user = bot.get_user(user_id) or ctx.guild.get_member(user_id)
                    if user:
                        await realtime_voice_processor.process_single_user_audio(
                            bytes(buffer), user.id, user.display_name, ctx.channel
                        )
            realtime_audio_buffers.pop(ctx.guild.id, None) # ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
            user_speaking_status.pop(ctx.guild.id, None) # çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
            for user_id, task in transcription_tasks.get(ctx.guild.id, {}).items():
                if not task.done():
                    print(f"æœªå®Œäº†ã®è»¢å†™ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«: {user_id}")
                    task.cancel() # ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
            transcription_tasks.pop(ctx.guild.id, None)

        await old_vc.disconnect()
        del connections[ctx.guild.id]
        await asyncio.sleep(0.5)

    # VoiceRecvClient ã‚’ä½¿ç”¨ã—ã¦æ¥ç¶š
    # listen=True ã§éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ä¿¡å¯èƒ½ã«ã™ã‚‹
    vc = await voice_channel.connect(cls=VoiceRecvClient, reconnect=True, listen=True)
    connections[ctx.guild.id] = vc
    vc.is_currently_recording = True # éŒ²éŸ³é–‹å§‹ãƒ•ãƒ©ã‚°ã‚’Trueã«è¨­å®š

    await ctx.send(f'ğŸµ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ« **{voice_channel.name}** ã«æ¥ç¶šã—ã¾ã—ãŸï¼')
    print(f'BotãŒãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ« {voice_channel.name} ã«æ¥ç¶šã—ã¾ã—ãŸã€‚')

    if not realtime_voice_processor.stt_handler or realtime_voice_processor.stt_handler.whisper_model is None:
        await ctx.send("âš ï¸ Whisperãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚STTæ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚Botã®ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        print("Whisperãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€VADæ©Ÿèƒ½ãªã—ã§éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    
    await ctx.send(
        f"ğŸ™ï¸ **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ç›£è¦–ãƒ»è»¢å†™ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼**\n"
        f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å…ˆ: `{AUDIO_OUTPUT_DIR}`\n"
        f"ğŸ¤– STT: {'âœ… ãƒ­ãƒ¼ã‚«ãƒ«Whisper' if realtime_voice_processor.stt_handler and realtime_voice_processor.stt_handler.whisper_model else 'âŒ ãªã—'}\n"
        f"â„¹ï¸ `!leave` ã§æ¥ç¶šã‚’åˆ‡æ–­ã§ãã¾ã™ã€‚"
    )
    print("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ç›£è¦–é–‹å§‹ã€‚")

@bot.command()
async def stop(ctx):
    """
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²éŸ³ã¯ `!leave` ã§åœæ­¢ã•ã‚Œã‚‹ãŸã‚ã€ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯ä¸è¦ã«ãªã‚‹ã‹ã€
    ä¸€æ™‚åœæ­¢ãªã©ã®åˆ¥ã®æ©Ÿèƒ½ã«å¤‰æ›´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
    ã“ã“ã§ã¯ã€ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®éŒ²éŸ³çŠ¶æ…‹ã‚’çµ‚äº†ã•ã›ã‚‹ã‚‚ã®ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚
    """
    if ctx.guild.id not in connections:
        await ctx.send("âŒ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«æ¥ç¶šã—ã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    vc = connections[ctx.guild.id]
    if hasattr(vc, 'is_currently_recording') and vc.is_currently_recording:
        vc.is_currently_recording = False # éŒ²éŸ³åœæ­¢ãƒ•ãƒ©ã‚°
        await ctx.send("â¸ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ç›£è¦–ã‚’ä¸€æ™‚åœæ­¢ã—ã¾ã—ãŸã€‚")
        print("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ç›£è¦–ã‚’ä¸€æ™‚åœæ­¢ã—ã¾ã—ãŸã€‚")
        
        # ç¾åœ¨ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ä¸­ã®éŸ³å£°ãŒã‚ã‚Œã°ã“ã“ã§å‡¦ç†
        if ctx.guild.id in realtime_audio_buffers:
            for user_id, pcm_data_buffer in realtime_audio_buffers[ctx.guild.id].items():
                if pcm_data_buffer:
                    user = bot.get_user(user_id) or ctx.guild.get_member(user_id)
                    if user:
                        await realtime_voice_processor.process_single_user_audio(
                            bytes(pcm_data_buffer), user_id, user.display_name, ctx.channel
                        )
            realtime_audio_buffers[ctx.guild.id].clear() # ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
            user_speaking_status[ctx.guild.id].clear() # çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
            for user_id, task in transcription_tasks.get(ctx.guild.id, {}).items():
                if not task.done():
                    print(f"æœªå®Œäº†ã®è»¢å†™ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«: {user_id}")
                    task.cancel()
            transcription_tasks[ctx.guild.id].clear()
            await ctx.send("âœ… æ®‹ã‚Šã®éŸ³å£°å‡¦ç†ã‚’å®Œäº†ã—ã¾ã—ãŸã€‚")
    else:
        await ctx.send("âŒ ç¾åœ¨ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ç›£è¦–ã¯è¡Œã‚ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

@bot.command()
async def leave(ctx):
    """ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰åˆ‡æ–­ã—ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°éŒ²éŸ³ã‚’åœæ­¢"""
    if ctx.guild.id not in connections:
        await ctx.send("âŒ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«æ¥ç¶šã—ã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    vc = connections[ctx.guild.id]
    
    # éŒ²éŸ³ä¸­ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã„ã‚Œã°ã€ãã®æ™‚ç‚¹ã¾ã§ã®éŸ³å£°ã‚’å‡¦ç†ã—ã¦åœæ­¢
    if hasattr(vc, 'is_currently_recording') and vc.is_currently_recording:
        vc.is_currently_recording = False
        await ctx.send("ğŸ›‘ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ç›£è¦–ã‚’åœæ­¢ã—ã¦ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰åˆ‡æ–­ã—ã¾ã™...")
        
        if ctx.guild.id in realtime_audio_buffers:
            for user_id, pcm_data_buffer in realtime_audio_buffers[ctx.guild.id].items():
                if pcm_data_buffer:
                    user = bot.get_user(user_id) or ctx.guild.get_member(user_id)
                    if user:
                        await realtime_voice_processor.process_single_user_audio(
                            bytes(pcm_data_buffer), user_id, user.display_name, ctx.channel
                        )
            realtime_audio_buffers.pop(ctx.guild.id, None) # ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
            user_speaking_status.pop(ctx.guild.id, None) # çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢

        # å®Ÿè¡Œä¸­ã®è»¢å†™ã‚¿ã‚¹ã‚¯ãŒã‚ã‚Œã°å¾…æ©Ÿã¾ãŸã¯ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        if ctx.guild.id in transcription_tasks:
            for user_id, task in transcription_tasks[ctx.guild.id].items():
                if not task.done():
                    print(f"æœªå®Œäº†ã®è»¢å†™ã‚¿ã‚¹ã‚¯ã‚’å¾…æ©Ÿ: {user_id}")
                    try:
                        await asyncio.wait_for(task, timeout=10.0) # 10ç§’å¾…æ©Ÿ
                    except asyncio.TimeoutError:
                        print(f"è»¢å†™ã‚¿ã‚¹ã‚¯ {user_id} ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã™ã€‚")
                        task.cancel()
            transcription_tasks.pop(ctx.guild.id, None)

    await vc.disconnect()
    if ctx.guild.id in connections:
        del connections[ctx.guild.id]
    await ctx.send("ğŸ‘‹ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰åˆ‡æ–­ã—ã¾ã—ãŸã€‚")
    print('BotãŒãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰åˆ‡æ–­ã—ã¾ã—ãŸã€‚')

# ... (on_ready, hello, register_voice, status, test_stt ã‚³ãƒãƒ³ãƒ‰ã¯åŸºæœ¬çš„ã«ãã®ã¾ã¾) ...

@bot.event
async def on_ready():
    """BotãŒDiscordã«æ¥ç¶šã—ãŸã¨ãã«å‘¼ã°ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ"""
    print(f'{bot.user} ãŒDiscordã«æ¥ç¶šã—ã¾ã—ãŸï¼')
    print(f'Bot ID: {bot.user.id}')
    global WHISPER_MODEL
    try:
        print(f"Whisperãƒ¢ãƒ‡ãƒ« ({WHISPER_MODEL_SIZE}, {WHISPER_DEVICE}, {WHISPER_COMPUTE_TYPE}) ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        WHISPER_MODEL = WhisperModel(WHISPER_MODEL_SIZE, device=WHISPER_DEVICE, compute_type=WHISPER_COMPUTE_TYPE)
        print("Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        # ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚‰STTãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã¨VoiceDataProcessorã‚’å†åˆæœŸåŒ–
        realtime_voice_processor.stt_handler = SpeechToTextHandler(WHISPER_MODEL)
    except Exception as e:
        print(f"Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        WHISPER_MODEL = None
    print(f'åˆ©ç”¨å¯èƒ½ãªSTT: {"âœ… ãƒ­ãƒ¼ã‚«ãƒ«Whisper" if WHISPER_MODEL else "âŒ ãªã—"}')

# ãƒœãƒƒãƒˆã®å®Ÿè¡Œ
if DISCORD_BOT_TOKEN:
    bot.run(DISCORD_BOT_TOKEN)
else:
    print("ã‚¨ãƒ©ãƒ¼: Discord Botãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚'.env'ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
