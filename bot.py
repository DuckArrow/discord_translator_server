import os
import discord
from discord.ext import commands
from dotenv import load_dotenv
import asyncio
import time
import wave
import io
import json
from typing import Optional, Dict, Any
import tempfile # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆãƒ»ç®¡ç†ç”¨

# faster-whisperã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from faster_whisper import WhisperModel

# .env ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰
load_dotenv()

# å„ç¨®ãƒˆãƒ¼ã‚¯ãƒ³ãƒ»APIã‚­ãƒ¼ã‚’å–å¾—
DISCORD_BOT_TOKEN = os.getenv("DISCORD_BOT_TOKEN")
# OpenAI API ã‚­ãƒ¼ã¯ãƒ­ãƒ¼ã‚«ãƒ«Whisperã§ã¯ä¸è¦ã«ãªã‚Šã¾ã™
# OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") 
GOOGLE_CLOUD_API_KEY = os.getenv("GOOGLE_CLOUD_API_KEY") # ç¾åœ¨ã¯æœªä½¿ç”¨

# Botã®ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆã‚’è¨­å®š
intents = discord.Intents.default()
intents.message_content = True
intents.voice_states = True
intents.members = True

# Botã®åˆæœŸåŒ–
bot = commands.Bot(command_prefix='!', intents=intents)

# éŸ³å£°ãƒ‡ãƒ¼ã‚¿ä¿å­˜ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
AUDIO_OUTPUT_DIR = "recorded_audio"
os.makedirs(AUDIO_OUTPUT_DIR, exist_ok=True)

# ãƒ¦ãƒ¼ã‚¶ãƒ¼éŸ³å£°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç† (ç¾åœ¨ã¯æœªä½¿ç”¨ã€å°†æ¥ã®è©±è€…è­˜åˆ¥å¼·åŒ–ç”¨)
user_voice_profiles: Dict[int, Dict[str, Any]] = {}
# ã‚®ãƒ«ãƒ‰ã”ã¨ã®ãƒœã‚¤ã‚¹æ¥ç¶šã‚’ç®¡ç†
connections: Dict[int, discord.VoiceClient] = {}

# faster-whisper ãƒ¢ãƒ‡ãƒ«ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
# Botèµ·å‹•æ™‚ã«ä¸€åº¦ã ã‘ãƒ­ãƒ¼ãƒ‰
# ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’é¸æŠ (tiny, base, small, medium, large)
# device="cpu" ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§CPUã‚’ä½¿ç”¨ã€‚GPUãŒã‚ã‚‹å ´åˆã¯ device="cuda"
# compute_type="int8" ã¯ã‚ˆã‚Šå°‘ãªã„ãƒ¡ãƒ¢ãƒªã¨é«˜é€Ÿãªæ¨è«–ã‚’æä¾›ã—ã¾ã™ãŒã€ç²¾åº¦ã«å½±éŸ¿ã™ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
# ã‚ˆã‚Šé«˜ã„ç²¾åº¦ãŒå¿…è¦ãªå ´åˆã¯ "float16" ã‚„ "float32" ã‚’è©¦ã—ã¦ãã ã•ã„ã€‚
WHISPER_MODEL: Optional[WhisperModel] = None
WHISPER_MODEL_SIZE = "base" # æ¨å¥¨: "base" ã¾ãŸã¯ "small"
WHISPER_DEVICE = "cpu" # GPUãŒã‚ã‚‹å ´åˆã¯ "cuda" ã‚’è©¦ã™
WHISPER_COMPUTE_TYPE = "int8" # CPUã®å ´åˆã¯ "int8" ãŒåŠ¹ç‡çš„


class SpeechToTextHandler:
    """Speech to Text (STT) å‘¼ã³å‡ºã—ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, whisper_model: WhisperModel):
        self.whisper_model = whisper_model

    async def transcribe_with_local_whisper(self, audio_file_path: str) -> Optional[str]:
        """faster-whisper ã‚’ä½¿ç”¨ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã§éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"""
        if self.whisper_model is None:
            print("Whisper ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return None
        
        try:
            # faster-whisperã§éŸ³å£°ã‚’è»¢å†™
            # language='ja' ã§æ—¥æœ¬èªã‚’æŒ‡å®šã€vad_filter=True ã§ç„¡éŸ³éƒ¨åˆ†ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            segments, info = self.whisper_model.transcribe(
                audio_file_path, 
                language="ja", 
                beam_size=5, # æ¨è«–ã®ãƒ“ãƒ¼ãƒ ã‚µã‚¤ã‚º
                vad_filter=True # ç„¡éŸ³éƒ¨åˆ†ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹ã«ã™ã‚‹
            )
            
            transcription_text = []
            for segment in segments:
                transcription_text.append(segment.text)
            
            return "".join(transcription_text)

        except FileNotFoundError:
            print(f"ä¸€æ™‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {audio_file_path}")
            return None
        except Exception as e:
            print(f"ãƒ­ãƒ¼ã‚«ãƒ«WhisperéŸ³å£°è»¢å†™ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    @staticmethod
    async def transcribe_with_google(audio_file_path: str, unique_id: str) -> Optional[str]:
        """Google Cloud Speech-to-Text APIã‚’ä½¿ç”¨ï¼ˆæœªå®Ÿè£…ï¼‰"""
        # Google Cloud STT APIã®å®Ÿè£…ã¯åˆ¥é€”å¿…è¦ã§ã™ã€‚
        # å®Ÿéš›ã®å®Ÿè£…ã¯Google Cloud SDKã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨
        print("Google Cloud STT APIã¯ç¾åœ¨å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return None

class VoiceDataProcessor:
    """éŸ³å£°ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨STTå‡¦ç†ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, output_dir: str, stt_handler: SpeechToTextHandler):
        self.output_dir = output_dir
        self.stt_handler = stt_handler
        self.start_time = int(time.time())

    def identify_speaker(self, user_id: int, user_name: str) -> Dict[str, Any]:
        """è©±è€…è­˜åˆ¥å‡¦ç†ï¼ˆã“ã®ã‚³ãƒ¼ãƒ‰ã§ã¯Discordãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚’ä½¿ç”¨ï¼‰"""
        # Discordã®ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚’ç›´æ¥è©±è€…ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ãŸã‚ã€
        # é«˜åº¦ãªè©±è€…è­˜åˆ¥ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã“ã“ã«å®Ÿè£…ã™ã‚‹
        speaker_info = {
            'user_id': user_id,
            'user_name': user_name,
            'confidence': 1.0,  # Discord APIã‹ã‚‰ç›´æ¥å¾—ã‚‰ã‚Œã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼IDãªã®ã§ä¿¡é ¼åº¦100%
            'voice_characteristics': {
                'platform': 'Discord',
                'identification_method': 'discord_user_id'
            }
        }
        return speaker_info

    async def process_recorded_audio(self, sink: discord.sinks.WaveSink, channel: discord.TextChannel):
        """éŒ²éŸ³å®Œäº†å¾Œã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿å‡¦ç†"""
        print("ğŸµ éŒ²éŸ³å®Œäº† - éŸ³å£°ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–‹å§‹...")
        
        # è»¢å†™çµæœã‚’ä¸€æ™‚çš„ã«ä¿æŒã™ã‚‹ãƒªã‚¹ãƒˆ
        all_transcriptions = []

        try:
            # å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
            if not sink.audio_data:
                await channel.send("âš ï¸ éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚èª°ã‚‚è©±ã—ã¦ã„ãªã‹ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                print("éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                return

            for user_id, audio_data in sink.audio_data.items():
                # bot.get_user ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¾å­˜ã™ã‚‹ãŸã‚ã€get_guild.get_member ã‚‚è©¦ã™
                user = bot.get_user(user_id) or channel.guild.get_member(user_id)
                if not user:
                    print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ID {user_id} ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                    continue
                
                print(f"ğŸ‘¤ å‡¦ç†ä¸­: {user.display_name} (ID: {user_id})")
                
                # è©±è€…è­˜åˆ¥
                speaker_info = self.identify_speaker(user_id, user.display_name)
                
                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜
                # audio_data.file ã¯ io.BytesIO ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãªã®ã§ã€getvalue()ã§ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                temp_audio_path = await self.save_temp_audio_file(audio_data.file.getvalue(), user_id, user.display_name)
                
                if temp_audio_path:
                    # STTå‡¦ç†: faster-whisperã¯unique_idã‚’å¿…è¦ã¨ã—ãªã„ãŸã‚ã€å¼•æ•°ã‹ã‚‰å‰Šé™¤
                    transcription = await self.stt_handler.transcribe_with_local_whisper(temp_audio_path)
                    
                    if transcription and transcription.strip():
                        # çµæœã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
                        all_transcriptions.append(f"**{user.display_name}**: {transcription}")
                        
                        # è»¢å†™çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                        await self.save_transcription(user_id, user.display_name, transcription, speaker_info)
                    else:
                        print(f"âŒ {user.display_name} ã®éŸ³å£°è»¢å†™ã«å¤±æ•—ã—ã¾ã—ãŸ (ç©ºã¾ãŸã¯None)")
                        all_transcriptions.append(f"**{user.display_name}**: _(è»¢å†™å¤±æ•—ã¾ãŸã¯éŸ³å£°ãªã—)_")
                        
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ (finallyãƒ–ãƒ­ãƒƒã‚¯ã§ç¢ºå®Ÿã«è¡Œã†)
                    try:
                        os.remove(temp_audio_path)
                        print(f"ğŸ—‘ï¸ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {temp_audio_path}")
                    except Exception as e:
                        print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {temp_audio_path} - {e}")
                else:
                    print(f"âŒ {user.display_name} ã®ä¸€æ™‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            # å…¨ã¦ã®è»¢å†™çµæœã‚’Discordãƒãƒ£ãƒ³ãƒãƒ«ã«ã¾ã¨ã‚ã¦é€ä¿¡
            if all_transcriptions:
                message_parts = []
                current_message = "--- å…¨ã¦ã®è»¢å†™çµæœ ---\n"
                for entry in all_transcriptions:
                    # Discordã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ–‡å­—æ•°åˆ¶é™ (ç´„2000æ–‡å­—) ã‚’è€ƒæ…®
                    if len(current_message) + len(entry) + 4 > 1990: # å°‘ã—ä½™è£•ã‚’æŒãŸã›ã‚‹
                        message_parts.append(current_message)
                        current_message = ""
                    current_message += entry + "\n"
                if current_message.strip() != "--- å…¨ã¦ã®è»¢å†™çµæœ ---": # æ®‹ã‚Šã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
                    message_parts.append(current_message)
                
                for msg_part in message_parts:
                    await channel.send(msg_part)
                await channel.send("âœ… å…¨ã¦ã®éŸ³å£°å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            else:
                await channel.send("â„¹ï¸ å‡¦ç†å¯¾è±¡ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        except Exception as e:
            print(f"éŸ³å£°ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            await channel.send(f"âŒ éŸ³å£°å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

    async def save_temp_audio_file(self, pcm_data: bytes, user_id: int, username: str) -> Optional[str]:
        """PCMãƒ‡ãƒ¼ã‚¿ã‚’WAVå½¢å¼ã§ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            # NamedTemporaryFileã¯è‡ªå‹•ã§ã‚ªãƒ¼ãƒ—ãƒ³ã•ã‚Œã‚‹ãŸã‚ã€ã‚¯ãƒ­ãƒ¼ã‚ºã—ã¦ã‹ã‚‰ãƒ‘ã‚¹ã‚’ä½¿ç”¨
            with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_file:
                temp_path = temp_file.name
                
            # waveãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦æ›¸ãè¾¼ã¿
            with wave.open(temp_path, 'wb') as wf:
                wf.setnchannels(2)    # ã‚¹ãƒ†ãƒ¬ã‚ª
                wf.setsampwidth(2)    # 16-bit (2ãƒã‚¤ãƒˆ/ã‚µãƒ³ãƒ—ãƒ«)
                wf.setframerate(48000) # 48kHz
                wf.writeframes(pcm_data) # PCMãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã‚€
            
            print(f"ğŸ“ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {username} -> {temp_path}")
            return temp_path
            
        except Exception as e:
            print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼ ({username}): {e}")
            return None

    async def save_transcription(self, user_id: int, username: str, transcription: str, speaker_info: Dict):
        """è»¢å†™çµæœã‚’JSONLå½¢å¼ã§ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        transcript_file = os.path.join(self.output_dir, f"transcriptions_{self.start_time}.jsonl")
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        
        transcript_entry = {
            'timestamp': timestamp,
            'user_id': user_id,
            'username': username,
            'transcription': transcription,
            'speaker_info': speaker_info
        }
        
        try:
            with open(transcript_file, 'a', encoding='utf-8') as f:
                f.write(f"{json.dumps(transcript_entry, ensure_ascii=False)}\n")
            print(f"ğŸ’¾ è»¢å†™çµæœä¿å­˜: {transcript_file}")
        except Exception as e:
            print(f"è»¢å†™çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªéŸ³å£°ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ã‚»ãƒƒã‚µ
# STTãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’åˆæœŸåŒ–ã™ã‚‹éš›ã«ã€ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®WHISPER_MODELã‚’æ¸¡ã™
# on_readyã§WHISPER_MODELãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ãŸã‚ã€åˆæœŸæ®µéšã§ã¯Noneã®å¯èƒ½æ€§ãŒã‚ã‚‹
# å®Ÿéš›ã«ã¯on_readyã§å†åˆæœŸåŒ–ã•ã‚Œã‚‹
voice_processor = VoiceDataProcessor(AUDIO_OUTPUT_DIR, SpeechToTextHandler(None)) # åˆæœŸæ®µéšã§ã¯Noneã‚’æ¸¡ã™

async def once_done(sink: discord.sinks.WaveSink, channel: discord.TextChannel, *args):
    """éŒ²éŸ³å®Œäº†æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°"""
    # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ãŒé–‰ã˜ã¦ã„ã‚‹å ´åˆã¯å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—
    if bot.loop.is_closed():
        print("è­¦å‘Š: ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ãŒé–‰ã˜ã¦ã„ã‚‹ãŸã‚ã€éŒ²éŸ³å®Œäº†å¾Œã®å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return
    
    print("ğŸ›‘ éŒ²éŸ³ãŒå®Œäº†ã—ã¾ã—ãŸã€‚éŸ³å£°å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
    # éŒ²éŸ³ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹
    # voice_processor ã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«ã§å®šç¾©ã•ã‚Œã¦ãŠã‚Šã€on_readyã§STTãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒæ›´æ–°ã•ã‚Œã‚‹
    await voice_processor.process_recorded_audio(sink, channel)
    
    # éŒ²éŸ³çµ‚äº†æ™‚ã€VoiceClientã® recording_state ã‚’ False ã«è¨­å®š
    # ã‚®ãƒ«ãƒ‰IDã‚’ä½¿ã£ã¦connectionsã‹ã‚‰VoiceClientã‚’å–å¾—
    vc = connections.get(channel.guild.id)
    if vc:
        vc.is_currently_recording = False # éŒ²éŸ³çŠ¶æ…‹ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ

    # æ¥ç¶šã‚’connectionsã‹ã‚‰å‰Šé™¤ï¼ˆã‚®ãƒ«ãƒ‰ãŒåˆ‡æ–­ã•ã‚ŒãŸã¨ãã‚‚è€ƒæ…®ï¼‰
    if channel.guild.id in connections:
        # vc.disconnect() ã¯ leave ã‚³ãƒãƒ³ãƒ‰ã§å®Ÿè¡Œã•ã‚Œã‚‹ã¹ããªã®ã§ã€ã“ã“ã§ã¯è¡Œã‚ãªã„
        # ãŸã ã—ã€BotãŒåˆ‡æ–­ã•ã‚Œãªã„é™ã‚Šconnectionsã«æ®‹ã—ã¦ãŠãã®ãŒé©åˆ‡
        pass # connectionsã‹ã‚‰ã®å‰Šé™¤ã¯ leave ã‚³ãƒãƒ³ãƒ‰ã«ä»»ã›ã‚‹


@bot.event
async def on_ready():
    """BotãŒDiscordã«æ¥ç¶šã—ãŸã¨ãã«å‘¼ã°ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ"""
    print(f'{bot.user} ãŒDiscordã«æ¥ç¶šã—ã¾ã—ãŸï¼')
    print(f'Bot ID: {bot.user.id}')
    # Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    global WHISPER_MODEL
    try:
        print(f"Whisperãƒ¢ãƒ‡ãƒ« ({WHISPER_MODEL_SIZE}, {WHISPER_DEVICE}, {WHISPER_COMPUTE_TYPE}) ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        # PyTorchãŒCPU/GPUã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨äº’æ›æ€§ãŒã‚ã‚‹ã‹ç¢ºèª
        # deviceãŒ"cuda"ã®å ´åˆã€GPUã®åˆ©ç”¨å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã“ã¨ãŒæœ›ã¾ã—ã„
        WHISPER_MODEL = WhisperModel(WHISPER_MODEL_SIZE, device=WHISPER_DEVICE, compute_type=WHISPER_COMPUTE_TYPE)
        print("Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        # ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚‰STTãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã¨VoiceDataProcessorã‚’å†åˆæœŸåŒ–
        voice_processor.stt_handler = SpeechToTextHandler(WHISPER_MODEL)
    except Exception as e:
        print(f"Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        WHISPER_MODEL = None # ãƒ­ãƒ¼ãƒ‰å¤±æ•—æ™‚ã¯Noneã«ã™ã‚‹

    print(f'åˆ©ç”¨å¯èƒ½ãªSTT: {"âœ… ãƒ­ãƒ¼ã‚«ãƒ«Whisper" if WHISPER_MODEL else "âŒ ãªã—"}')


@bot.event
async def on_voice_state_update(member, before, after):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«çŠ¶æ…‹æ›´æ–°ã‚¤ãƒ™ãƒ³ãƒˆ"""
    if member == bot.user:
        return

    # BotãŒæ¥ç¶šã—ã¦ã„ã‚‹ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå‚åŠ /é€€å‡ºã—ãŸå ´åˆã‚’æ¤œçŸ¥
    # (connectionsè¾æ›¸ã§BotãŒæ¥ç¶šä¸­ã®ã‚®ãƒ«ãƒ‰ã‚’è¿½è·¡)
    if member.guild.id in connections:
        vc = connections[member.guild.id]
        if vc.channel == before.channel and vc.channel != after.channel:
            print(f'{member.display_name} ãŒ {before.channel.name} ã‹ã‚‰é€€å‡ºã—ã¾ã—ãŸã€‚')
        elif vc.channel != before.channel and vc.channel == after.channel:
            print(f'{member.display_name} ãŒ {after.channel.name} ã«å‚åŠ ã—ã¾ã—ãŸã€‚')

@bot.command()
async def hello(ctx):
    """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚¹ãƒˆã‚³ãƒãƒ³ãƒ‰"""
    await ctx.send(f'ã“ã‚“ã«ã¡ã¯ã€{ctx.author.display_name}ã•ã‚“ï¼')

@bot.command()
async def join(ctx):
    """ãƒœãƒƒãƒˆã‚’ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«æ¥ç¶šã—ã€éŸ³å£°éŒ²éŸ³ãƒ»è»¢å†™ã‚’é–‹å§‹"""
    if ctx.author.voice is None:
        await ctx.send("âŒ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«æ¥ç¶šã—ã¦ãã ã•ã„ã€‚")
        return

    voice_channel = ctx.author.voice.channel
    
    # æ—¢å­˜ã®æ¥ç¶šãŒã‚ã‚Œã°åˆ‡æ–­
    if ctx.guild.id in connections:
        old_vc = connections[ctx.guild.id]
        # éŒ²éŸ³ä¸­ã®å ´åˆã¯åœæ­¢ (ã‚«ã‚¹ã‚¿ãƒ ãƒ•ãƒ©ã‚°ã‚’ä½¿ç”¨)
        if hasattr(old_vc, 'is_currently_recording') and old_vc.is_currently_recording:
            old_vc.stop_recording()
            old_vc.is_currently_recording = False # ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
        await old_vc.disconnect()
        del connections[ctx.guild.id] # å¤ã„æ¥ç¶šã‚’å‰Šé™¤
        await asyncio.sleep(0.5)

    # ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«æ¥ç¶š
    vc = await voice_channel.connect()
    connections[ctx.guild.id] = vc # æ–°ã—ã„æ¥ç¶šã‚’è¨˜éŒ²
    vc.is_currently_recording = False # åˆæœŸçŠ¶æ…‹ã‚’Falseã«è¨­å®š
    
    await ctx.send(f'ğŸµ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ« **{voice_channel.name}** ã«æ¥ç¶šã—ã¾ã—ãŸï¼')
    print(f'BotãŒãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ« {voice_channel.name} ã«æ¥ç¶šã—ã¾ã—ãŸã€‚')

    # STTãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
    # joinã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œæ™‚ã«voice_processorã®stt_handlerãŒé©åˆ‡ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
    if not voice_processor.stt_handler or voice_processor.stt_handler.whisper_model is None:
        await ctx.send("âš ï¸ Whisperãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚STTæ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚Botã®ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        print("Whisperãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€STTæ©Ÿèƒ½ãªã—ã§éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
        pass # STTãŒNoneã§ã‚‚ç¶šè¡Œã—ã€process_recorded_audioã§ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹

    # WaveSinkã‚’ä½¿ç”¨ã—ã¦éŒ²éŸ³é–‹å§‹
    sink = discord.sinks.WaveSink()
    # ä¿®æ­£: bot.loop.call_soon_threadsafe ã‚’ä½¿ç”¨ã—ã¦ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
    #       asyncio.create_task ã®å‘¼ã³å‡ºã—ã¯ call_soon_threadsafe ã®å†…éƒ¨ã§è¡Œã‚ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
    vc.start_recording(
        sink,
        lambda s: bot.loop.call_soon_threadsafe(once_done, s, ctx.channel),
    )
    vc.is_currently_recording = True # éŒ²éŸ³é–‹å§‹ãƒ•ãƒ©ã‚°ã‚’Trueã«è¨­å®š
    
    await ctx.send(
        f"ğŸ™ï¸ **éŸ³å£°éŒ²éŸ³ãƒ»è»¢å†™ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼**\n"
        f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å…ˆ: `{AUDIO_OUTPUT_DIR}`\n"
        f"ğŸ¤– STT: {'âœ… ãƒ­ãƒ¼ã‚«ãƒ«Whisper' if voice_processor.stt_handler and voice_processor.stt_handler.whisper_model else 'âŒ ãªã—'}\n"
        f"â„¹ï¸ `!stop` ã§éŒ²éŸ³ã‚’åœæ­¢ã§ãã¾ã™ã€‚"
    )
    print(f"éŸ³å£°éŒ²éŸ³é–‹å§‹: {AUDIO_OUTPUT_DIR}")

@bot.command()
async def stop(ctx):
    """éŸ³å£°éŒ²éŸ³ã‚’åœæ­¢"""
    if ctx.guild.id not in connections:
        await ctx.send("âŒ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«æ¥ç¶šã—ã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    vc = connections[ctx.guild.id]
    
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ•ãƒ©ã‚°ã§éŒ²éŸ³ä¸­ã‹ç¢ºèª
    if hasattr(vc, 'is_currently_recording') and vc.is_currently_recording:
        vc.stop_recording() # éŒ²éŸ³ã‚’åœæ­¢ã™ã‚‹ã¨once_doneãŒå‘¼ã°ã‚Œã‚‹
        # once_doneã§ is_currently_recording ãŒFalseã«è¨­å®šã•ã‚Œã‚‹
        await ctx.send("ğŸ›‘ éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚éŸ³å£°å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
        print("éŸ³å£°éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")
    else:
        await ctx.send("âŒ ç¾åœ¨éŒ²éŸ³ã—ã¦ã„ã¾ã›ã‚“ã€‚")

@bot.command()
async def leave(ctx):
    """ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰åˆ‡æ–­"""
    if ctx.guild.id not in connections:
        await ctx.send("âŒ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«æ¥ç¶šã—ã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    vc = connections[ctx.guild.id]
    
    # éŒ²éŸ³ä¸­ãªã‚‰åœæ­¢ (ã‚«ã‚¹ã‚¿ãƒ ãƒ•ãƒ©ã‚°ã‚’ä½¿ç”¨)
    if hasattr(vc, 'is_currently_recording') and vc.is_currently_recording:
        vc.stop_recording()
        vc.is_currently_recording = False # ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
        await ctx.send("ğŸ›‘ éŒ²éŸ³ã‚’åœæ­¢ã—ã¦ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰åˆ‡æ–­ã—ã¾ã™...")
    
    await vc.disconnect()
    if ctx.guild.id in connections: # å¿µã®ãŸã‚connectionsã‹ã‚‰ã‚‚å‰Šé™¤
        del connections[ctx.guild.id]
    await ctx.send("ğŸ‘‹ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰åˆ‡æ–­ã—ã¾ã—ãŸã€‚")
    print('BotãŒãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰åˆ‡æ–­ã—ã¾ã—ãŸã€‚')

@bot.command()
async def register_voice(ctx):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éŸ³å£°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™»éŒ²ï¼ˆå°†æ¥ã®è©±è€…è­˜åˆ¥ç”¨ï¼‰"""
    # ã“ã®æ©Ÿèƒ½ã¯é«˜åº¦ãªè©±è€…è­˜åˆ¥ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè£…ãŒå¿…è¦ã§ã™ã€‚
    # ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã§ã¯Discordãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚’è©±è€…ã¨ã—ã¦åˆ©ç”¨ã—ã¦ã„ã¾ã™ã€‚
    await ctx.send("ğŸ¤ ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯ã€é«˜åº¦ãªè©±è€…è­˜åˆ¥æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚ŒãŸéš›ã«åˆ©ç”¨ã§ãã¾ã™ã€‚")

@bot.command()
async def status(ctx):
    """ç¾åœ¨ã®éŒ²éŸ³çŠ¶æ³ã‚’ç¢ºèª"""
    if ctx.guild.id not in connections:
        await ctx.send("âŒ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«æ¥ç¶šã—ã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    vc = connections[ctx.guild.id]
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ•ãƒ©ã‚°ã§éŒ²éŸ³ä¸­ã‹ç¢ºèª
    if hasattr(vc, 'is_currently_recording') and vc.is_currently_recording:
        channel_members = len(vc.channel.members) - 1  # Botè‡ªèº«ã‚’é™¤ã
        await ctx.send(f"ğŸ“Š éŒ²éŸ³ä¸­ã§ã™ã€‚ãƒãƒ£ãƒ³ãƒãƒ«å†…ã®ãƒ¡ãƒ³ãƒãƒ¼æ•°: {channel_members}äººã€‚")
    else:
        await ctx.send("â¸ï¸ ç¾åœ¨éŒ²éŸ³ã—ã¦ã„ã¾ã›ã‚“ã€‚")

@bot.command()
async def test_stt(ctx):
    """STTæ©Ÿèƒ½ã®æ¥ç¶šãƒ†ã‚¹ãƒˆ"""
    if WHISPER_MODEL:
        await ctx.send(f"âœ… ãƒ­ãƒ¼ã‚«ãƒ«Whisperãƒ¢ãƒ‡ãƒ« ({WHISPER_MODEL_SIZE}, {WHISPER_DEVICE}) è¨­å®šæ¸ˆã¿ - STTæ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
    else:
        await ctx.send("âŒ STTæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

# Botã®å®Ÿè¡Œ
if DISCORD_BOT_TOKEN:
    bot.run(DISCORD_BOT_TOKEN)
else:
    print("ã‚¨ãƒ©ãƒ¼: Discord Botãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚'.env'ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
