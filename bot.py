import os
import discord
from discord.ext import commands
from dotenv import load_dotenv
import asyncio
import time
import wave
import io
import json
import tempfile # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆãƒ»ç®¡ç†ç”¨
import threading # æ–‡å­—èµ·ã“ã—å‡¦ç†ã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
import queue # ã‚¹ãƒ¬ãƒƒãƒ‰é–“ã®ãƒ‡ãƒ¼ã‚¿é€šä¿¡ç”¨
from collections import deque # åŠ¹ç‡çš„ãªãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ç”¨
from typing import Optional, Dict, Any, List
import numpy as np # éŸ³å£°ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç”¨
import shutil # ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼ç”¨

# faster-whisperã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from faster_whisper import WhisperModel

# discord-ext-voice-recv ã®æ­£ã—ã„ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–¹æ³•
from discord.ext.voice_recv import VoiceRecvClient
from discord.ext.voice_recv import AudioSink # AudioSinkã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™
from discord.ext.voice_recv import VoiceData # VoiceDataã®å‹ãƒ’ãƒ³ãƒˆã®ãŸã‚ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# VAD (Voice Activity Detection) ç”¨
import webrtcvad

# â˜…â˜…â˜… è¨­å®š â˜…â˜…â˜…
REALTIME_CHUNK_DURATION_MS = 1200  # 1200msï¼ˆ1.2ç§’ï¼‰
VAD_AGGRESSIVENESS = 0  # WebRTC VADã®æ„Ÿåº¦ã‚’èª¿æ•´ (0-3, 0ãŒæœ€ã‚‚å¯›å®¹)
MIN_SPEECH_DURATION_MS = 300  # æœ€å°ç™ºè©±æ™‚é–“ï¼ˆ300msï¼‰
SILENCE_THRESHOLD_MS = 1000 # ç„¡éŸ³æ™‚é–“ãŒã“ã‚Œã‚’è¶…ãˆã‚‹ã¨ç™ºè©±çµ‚äº†ã¨ã¿ãªã™
OVERLAP_DURATION_MS = 200  # ãƒãƒ£ãƒ³ã‚¯é–“ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—

# éŸ³å£°å“è³ªè¨­å®šï¼ˆ16kHzã«å¤‰æ›´ã—ã¦Whisperã®å‡¦ç†ã‚’é«˜é€ŸåŒ–ï¼‰
WHISPER_SAMPLE_RATE = 16000  # Whisperã®æ¨å¥¨ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ
PCM_SAMPLE_RATE = 48000  # Discordã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿
PCM_BYTES_PER_SAMPLE = 2
PCM_CHANNELS = 2

# è¨ˆç®—ç”¨å®šæ•°
REALTIME_CHUNK_SAMPLES = int(WHISPER_SAMPLE_RATE * REALTIME_CHUNK_DURATION_MS / 1000)
REALTIME_CHUNK_BYTES = REALTIME_CHUNK_SAMPLES * 2  # 16-bit mono (2 bytes per sample)

# .env ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰
load_dotenv()

DISCORD_BOT_TOKEN = os.getenv("DISCORD_BOT_TOKEN")

# Botã®ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆã‚’è¨­å®š
intents = discord.Intents.default()
intents.message_content = True
intents.voice_states = True
intents.members = True

# Botã®åˆæœŸåŒ–
bot = commands.Bot(command_prefix='!', intents=intents)

# éŸ³å£°ãƒ‡ãƒ¼ã‚¿ä¿å­˜ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
AUDIO_OUTPUT_DIR = "recorded_audio"
os.makedirs(AUDIO_OUTPUT_DIR, exist_ok=True)

# ãƒ‡ãƒãƒƒã‚°ç”¨éŸ³å£°ä¿å­˜è¨­å®š
SAVE_DEBUG_AUDIO = False
DEBUG_AUDIO_SAVE_DIR = os.path.join(AUDIO_OUTPUT_DIR, "debug_recordings")
os.makedirs(DEBUG_AUDIO_SAVE_DIR, exist_ok=True) # Ensure directory exists

# ã‚®ãƒ«ãƒ‰ã”ã¨ã®ãƒœã‚¤ã‚¹æ¥ç¶šã‚’ç®¡ç†
connections: Dict[int, VoiceRecvClient] = {}

# Whisperãƒ¢ãƒ‡ãƒ«ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
WHISPER_MODEL: Optional[WhisperModel] = None
WHISPER_MODEL_SIZE = "small" 
WHISPER_DEVICE = "cpu"
WHISPER_COMPUTE_TYPE = "int8"

# æŠ‘åˆ¶ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ã‚ºã®ãƒªã‚¹ãƒˆã‚’å®šç¾©
# ç’°å¢ƒéŸ³ãªã©ã§èª¤èªè­˜ã•ã‚Œã‚„ã™ã„ãƒ•ã‚£ãƒ©ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„ã€å‡ºåŠ›ã—ãŸããªã„ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ã“ã“ã«ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã™ã€‚
HALLUCINATION_TEXTS = [
    "ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ", "ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚",
    "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ", "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚",
    "ã©ã†ã‚‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ", "ã©ã†ã‚‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚",
    "ã©ã†ã‚‚ã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ", "ã©ã†ã‚‚ã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚",
    "ãŠã‚„ã™ã¿ãªã•ã„", "ãŠã‚„ã™ã¿ãªã•ã„ã€‚",
    "Thanks for watching!",
    "çµ‚ã‚ã‚Š", "ãŠã‚ã‚Š",
    "ãŠç–²ã‚Œæ§˜ã§ã—ãŸ", "ãŠç–²ã‚Œæ§˜ã§ã—ãŸã€‚",
]


class AudioUtils:
    """éŸ³å£°ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def resample_audio(audio_data: bytes, original_rate: int, target_rate: int) -> bytes:
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æŒ‡å®šã®ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # Discordã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã¯ã‚¹ãƒ†ãƒ¬ã‚ªãªã®ã§ã€ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›
        audio_array = np.frombuffer(audio_data, dtype=np.int16)
        
        # ã‚¹ãƒ†ãƒ¬ã‚ªã®å ´åˆã€å·¦å³ã®ãƒãƒ£ãƒ³ãƒãƒ«ã®å¹³å‡ã‚’å–ã£ã¦ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›
        if audio_array.shape[0] % PCM_CHANNELS == 0:
            audio_array = audio_array.reshape(-1, PCM_CHANNELS).mean(axis=1).astype(np.int16)
        
        # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒå¿…è¦ãªå ´åˆ
        if original_rate != target_rate:
            # ç°¡æ˜“ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆã‚ˆã‚Šé«˜å“è³ªãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ï¼‰
            ratio = target_rate / original_rate
            new_length = int(len(audio_array) * ratio)
            resampled = np.interp(
                np.linspace(0, len(audio_array) - 1, new_length),
                np.arange(len(audio_array)),
                audio_array
            ).astype(np.int16)
            return resampled.tobytes()
        else:
            return audio_array.tobytes()
    
    @staticmethod
    def apply_vad(audio_data: bytes, sample_rate: int, vad_aggressiveness: int = 2) -> bool:
        """WebRTC VADã‚’ä½¿ç”¨ã—ã¦éŸ³å£°æ´»å‹•ã‚’æ¤œå‡º"""
        try:
            vad = webrtcvad.Vad(vad_aggressiveness)
            
            # VADã¯ç‰¹å®šã®ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚ºã«å¯¾å¿œ
            if sample_rate not in [8000, 16000, 32000, 48000]:
                print(f"DEBUG VAD: Unsupported sample rate {sample_rate}. Assuming speech.")
                return True  # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã®å ´åˆã¯éŸ³å£°ã‚ã‚Šã¨ã¿ãªã™
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚ºï¼ˆ10ms, 20ms, 30msï¼‰
            # WebRTC VADã¯ã€ã“ã‚Œã‚‰ã®ã„ãšã‚Œã‹ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚ºã§å‡¦ç†ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
            # ã“ã“ã§ã¯30msã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
            frame_duration_ms = 30
            frame_size = int(sample_rate * frame_duration_ms / 1000) * 2  # 16-bit mono
            
            if len(audio_data) < frame_size:
                # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚ºã‚ˆã‚Šã‚‚ãƒ‡ãƒ¼ã‚¿ãŒçŸ­ã„å ´åˆã¯ã€éŸ³å£°ãªã—ã¨åˆ¤æ–­
                return False
                
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åˆ‡ã‚Šå‡ºã—ã¦VADã‚’é©ç”¨
            is_any_speech = False
            for i in range(0, len(audio_data) - frame_size + 1, frame_size):
                frame = audio_data[i:i + frame_size]
                if vad.is_speech(frame, sample_rate):
                    is_any_speech = True
                    break # éŸ³å£°ãŒæ¤œå‡ºã•ã‚ŒãŸã‚‰ã™ãã«ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
            
            return is_any_speech
        except Exception as e:
            print(f"DEBUG VAD: VADã‚¨ãƒ©ãƒ¼: {e}. éŸ³å£°ã‚ã‚Šã¨ã¿ãªã—ã¾ã™ã€‚")
            return True  # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯éŸ³å£°ã‚ã‚Šã¨ã¿ãªã™


class RealtimeTranscriptionEngine:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, whisper_model: WhisperModel, output_dir: str):
        self.whisper_model = whisper_model
        self.output_dir = output_dir
        self.transcription_queue = queue.Queue() # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¯ãƒ¼ã‚«ãƒ¼ã«é€ã‚‹ã‚­ãƒ¥ãƒ¼
        self.result_queue = queue.Queue() # ãƒ¯ãƒ¼ã‚«ãƒ¼ã‹ã‚‰çµæœã‚’å—ã‘å–ã‚‹ã‚­ãƒ¥ãƒ¼
        self.is_running = False
        self.worker_thread = None
        
    def start(self):
        """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ã‚’é–‹å§‹"""
        if not self.is_running:
            self.is_running = True
            self.worker_thread = threading.Thread(target=self._transcription_worker, daemon=True)
            self.worker_thread.start()
            print("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚¨ãƒ³ã‚¸ãƒ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
        
    def stop(self):
        """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ã‚’åœæ­¢"""
        self.is_running = False
        if self.worker_thread and self.worker_thread.is_alive():
            self.worker_thread.join(timeout=5.0) # ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒçµ‚äº†ã™ã‚‹ã®ã‚’å¾…æ©Ÿ
            print("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åœæ­¢ã—ã¾ã—ãŸ")
        
    def submit_audio(self, audio_data: bytes, user_id: int, username: str, guild_id: int):
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ """
        if self.is_running:
            self.transcription_queue.put({
                'audio_data': audio_data,
                'user_id': user_id,
                'username': username,
                'guild_id': guild_id,
                'timestamp': time.time()
            })
            print(f"DEBUG TranscriptionEngine: Submitted {len(audio_data)} bytes for {username} to queue.")
        
    def get_result(self) -> Optional[Dict]:
        """å‡¦ç†çµæœã‚’å–å¾—"""
        try:
            return self.result_queue.get_nowait()
        except queue.Empty:
            return None
        
    def _transcription_worker(self):
        """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§æ–‡å­—èµ·ã“ã—ã‚’å‡¦ç†ã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼"""
        while self.is_running:
            try:
                # ã‚¿ã‚¹ã‚¯ã‚’å–å¾—ï¼ˆ0.1ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰
                task = self.transcription_queue.get(timeout=0.1)
                
                audio_data = task['audio_data']
                if len(audio_data) < REALTIME_CHUNK_BYTES // 2: # ãƒãƒ£ãƒ³ã‚¯ã®åŠåˆ†æœªæº€ã¯ã‚¹ã‚­ãƒƒãƒ—
                    print(f"DEBUG Worker: Skipping too small audio chunk for {task['username']} ({len(audio_data)} bytes).")
                    continue
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_file:
                    temp_path = temp_file.name
                
                try:
                    # WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ (ãƒ¢ãƒãƒ©ãƒ«, 16kHz)
                    with wave.open(temp_path, 'wb') as wf:
                        wf.setnchannels(1)  # ãƒ¢ãƒãƒ©ãƒ«
                        wf.setsampwidth(2)  # 16-bit
                        wf.setframerate(WHISPER_SAMPLE_RATE)
                        wf.writeframes(audio_data)
                    
                    # ãƒ‡ãƒãƒƒã‚°ç”¨éŸ³å£°ä¿å­˜ãŒæœ‰åŠ¹ãªå ´åˆã€ã‚³ãƒ”ãƒ¼ã‚’ä¿å­˜
                    global SAVE_DEBUG_AUDIO, DEBUG_AUDIO_SAVE_DIR
                    if SAVE_DEBUG_AUDIO:
                        debug_save_filename = f"user_{task['user_id']}_{int(time.time())}.wav"
                        debug_save_path = os.path.join(DEBUG_AUDIO_SAVE_DIR, debug_save_filename)
                        shutil.copy(temp_path, debug_save_path)
                        print(f"DEBUG Worker: Saved debug audio to {debug_save_path}")

                    print(f"DEBUG Worker: Processing task for {task['username']}. Temp file: {temp_path}, Audio length: {len(audio_data)} bytes.")
                    
                    # Whisperã§æ–‡å­—èµ·ã“ã—
                    transcription = ""
                    if self.whisper_model:
                        segments, info = self.whisper_model.transcribe(
                            temp_path,
                            language="ja",
                            beam_size=5,  # ç²¾åº¦ã‚’é‡è¦–ã™ã‚‹ãŸã‚ãƒ“ãƒ¼ãƒ ã‚µã‚¤ã‚º5
                            vad_filter=True, # Whisperã®VADãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’æœ‰åŠ¹ã«ç¶­æŒ
                            no_speech_threshold=0.5, # ç²¾åº¦ã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ã®ãƒãƒ©ãƒ³ã‚¹
                            condition_on_previous_text=True,  # ç²¾åº¦ã‚’é‡è¦–ã™ã‚‹ãŸã‚æ–‡è„ˆä¾å­˜ã‚’æœ‰åŠ¹
                            patience=0.5 # â˜…â˜…â˜… patienceã‚’0.5ã«å†è¨­å®š â˜…â˜…â˜…
                        )
                        
                        for segment in segments:
                            transcription += segment.text
                    
                    # æ–‡å­—èµ·ã“ã—çµæœã‚’HALLUCINATION_TEXTSã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    stripped_transcription = transcription.strip()
                    if stripped_transcription and stripped_transcription not in HALLUCINATION_TEXTS:
                        self.result_queue.put({
                            'user_id': task['user_id'],
                            'username': task['username'],
                            'guild_id': task['guild_id'],
                            'transcription': stripped_transcription,
                            'timestamp': task['timestamp']
                        })
                        print(f"DEBUG Worker: Transcribed for {task['username']}: '{stripped_transcription}'. Result added to queue.")
                    else:
                        if stripped_transcription:
                            print(f"DEBUG Worker: Suppressed hallucination: '{stripped_transcription}' for {task['username']}.")
                        else:
                            print(f"DEBUG Worker: No transcription for {task['username']} (empty or stripped).")
                
                finally:
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    try:
                        os.remove(temp_path)
                        # print(f"DEBUG Worker: Cleaned up temp file: {temp_path}")
                    except Exception as cleanup_e:
                        print(f"DEBUG Worker: ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼ ({temp_path}): {cleanup_e}")
            
            except queue.Empty:
                # ã‚­ãƒ¥ãƒ¼ãŒç©ºã®å ´åˆã¯å¾…æ©Ÿ
                continue
            except Exception as e:
                print(f"ERROR: æ–‡å­—èµ·ã“ã—å‡¦ç†ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


class StreamingAudioBuffer:
    """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°ãƒãƒƒãƒ•ã‚¡ - å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éŸ³å£°ã‚’ä¸€æ™‚çš„ã«è“„ç©ã—ã€VADã§ç™ºè©±åŒºé–“ã‚’ç®¡ç†"""
    
    def __init__(self, user_id: int, username: str):
        self.user_id = user_id
        self.username = username
        self.audio_buffer = deque() # å—ä¿¡ã—ãŸç”Ÿã®PCMãƒ‡ãƒ¼ã‚¿ (Discordã‹ã‚‰ã®48kHzã‚¹ãƒ†ãƒ¬ã‚ª)
        self.last_speech_time = 0.0 # æœ€å¾Œã«éŸ³å£°ãŒæ¤œå‡ºã•ã‚ŒãŸæ™‚åˆ»
        self.is_speaking = False # ç¾åœ¨ç™ºè©±ä¸­ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°
        self.accumulated_audio = bytearray() # VADãƒ»ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å¾Œã®16kHzãƒ¢ãƒãƒ©ãƒ«éŸ³å£°ãƒ‡ãƒ¼ã‚¿

        # ãƒãƒ£ãƒ³ã‚¯ç®¡ç†ç”¨å¤‰æ•°
        self.last_processed_buffer_length = 0 # æœ€å¾Œã«å‡¦ç†ã—ãŸ accumulated_audio ã®é•·ã•
        
    def add_audio(self, audio_data: bytes) -> bool:
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã€VADã«åŸºã¥ã„ã¦ç™ºè©±ã®çŠ¶æ…‹ã‚’æ›´æ–°ã€‚ç™ºè©±çµ‚äº†ã‚’æ¤œå‡ºã—ãŸå ´åˆã¯Trueã‚’è¿”ã™ã€‚"""
        current_time = time.time()
        
        # 48kHzã‚¹ãƒ†ãƒ¬ã‚ªPCMã‚’16kHzãƒ¢ãƒãƒ©ãƒ«ã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        resampled_audio = AudioUtils.resample_audio(
            audio_data, PCM_SAMPLE_RATE, WHISPER_SAMPLE_RATE
        )
        
        # VADåˆ¤å®šã«ã‹ã‹ã‚ã‚‰ãšã€å¸¸ã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ•ã‚¡ã«è“„ç©ã™ã‚‹
        self.accumulated_audio.extend(resampled_audio) 

        # VADã§éŸ³å£°æ´»å‹•ã‚’æ¤œå‡º
        has_speech = AudioUtils.apply_vad(resampled_audio, WHISPER_SAMPLE_RATE, VAD_AGGRESSIVENESS)
        
        if has_speech:
            self.last_speech_time = current_time
            if not self.is_speaking:
                print(f"DEBUG Buffer: {self.username} -> Speech START detected.")
            self.is_speaking = True
        else:
            # ç„¡éŸ³æ™‚é–“ãŒé–¾å€¤ã‚’è¶…ãˆãŸå ´åˆã€ç™ºè©±çµ‚äº†ã¨ã¿ãªã™
            if self.is_speaking and (current_time - self.last_speech_time) > (SILENCE_THRESHOLD_MS / 1000):
                # Only signal speech end if there's actual accumulated audio to process
                if len(self.accumulated_audio) > 0: # Ensures we don't signal end on empty buffer
                    print(f"DEBUG Buffer: {self.username} -> Speech END detected. Accumulated audio length: {len(self.accumulated_audio)} bytes.")
                    self.is_speaking = False
                    return True  # ç™ºè©±çµ‚äº†ã‚’ç¤ºã™
                else:
                    self.is_speaking = False # No speech and buffer empty, so stop speaking
            # VADãŒä¸€æ™‚çš„ã«ç„¡éŸ³ã¨åˆ¤æ–­ã—ã¦ã‚‚ã€SILENCE_THRESHOLD_MSã«é”ã—ã¦ã„ãªã‘ã‚Œã°is_speakingã¯Trueã®ã¾ã¾
            # ã¾ãŸã€éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¯æ—¢ã«accumulated_audioã«è¿½åŠ æ¸ˆã¿
        
        return False
    
    def get_audio_chunk(self) -> Optional[bytes]:
        """è“„ç©ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€å›ºå®šã‚µã‚¤ã‚ºã®ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ã—ã¦è¿”ã™"""
        # accumulated_audio ã‹ã‚‰ã€ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚’è€ƒæ…®ã—ã¦å‡¦ç†ã™ã¹ãæ–°ã—ã„éƒ¨åˆ†ã‚’åˆ‡ã‚Šå‡ºã™
        new_data_length = len(self.accumulated_audio) - self.last_processed_buffer_length

        # REALTIME_CHUNK_BYTES ä»¥ä¸Šã®æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã«ãƒãƒ£ãƒ³ã‚¯ã‚’ç”Ÿæˆ
        if new_data_length >= REALTIME_CHUNK_BYTES:
            # å‡¦ç†ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ã®é–‹å§‹ä½ç½®ã‚’è¨ˆç®— (ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚’è€ƒæ…®)
            chunk_start_index = self.last_processed_buffer_length - int(REALTIME_CHUNK_BYTES * OVERLAP_DURATION_MS / REALTIME_CHUNK_DURATION_MS)
            if chunk_start_index < 0: # è² ã®å€¤ã«ãªã‚‰ãªã„ã‚ˆã†ã«
                chunk_start_index = 0

            # å‡¦ç†ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ã®çµ‚äº†ä½ç½®
            chunk_end_index = chunk_start_index + REALTIME_CHUNK_BYTES
            
            chunk = bytes(self.accumulated_audio[chunk_start_index:chunk_end_index])
            
            self.last_processed_buffer_length = chunk_end_index # å‡¦ç†ã—ãŸä½ç½®ã‚’æ›´æ–°
            print(f"DEBUG Buffer: {self.username} -> Extracted chunk of {len(chunk)} bytes. New accumulated length: {len(self.accumulated_audio)} bytes. Last processed: {self.last_processed_buffer_length}.")
            return chunk
        
        return None
    
    def get_remaining_audio(self) -> Optional[bytes]:
        """ãƒãƒƒãƒ•ã‚¡ã«æ®‹ã£ã¦ã„ã‚‹å…¨ã¦ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹"""
        if len(self.accumulated_audio) > 0:
            remaining_chunk = bytes(self.accumulated_audio)
            self.accumulated_audio.clear()
            self.last_processed_buffer_length = 0
            print(f"DEBUG Buffer: {self.username} -> Getting remaining audio of {len(remaining_chunk)} bytes.")
            return remaining_chunk
        return None


class RealtimeVoiceProcessor:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ - éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®å—ä¿¡ã¨æ–‡å­—èµ·ã“ã—ã‚¨ãƒ³ã‚¸ãƒ³ã¸ã®é€£æºã‚’ç®¡ç†"""
    
    def __init__(self, transcription_engine: RealtimeTranscriptionEngine):
        self.transcription_engine = transcription_engine
        self.audio_buffers: Dict[int, Dict[int, StreamingAudioBuffer]] = {}  # guild_id -> user_id -> buffer
        self.text_channels: Dict[int, discord.TextChannel] = {}  # guild_id -> channel
        self.result_polling_tasks: Dict[int, asyncio.Task] = {}  # guild_id -> task
        self.periodic_chunk_processing_tasks: Dict[int, asyncio.Task] = {} # Guild ID -> Task for periodic chunking
        
    def start_processing(self, guild_id: int, text_channel: discord.TextChannel):
        """æŒ‡å®šã•ã‚ŒãŸã‚®ãƒ«ãƒ‰ã®éŸ³å£°å‡¦ç†ã‚’é–‹å§‹"""
        self.text_channels[guild_id] = text_channel
        if guild_id not in self.audio_buffers:
            self.audio_buffers[guild_id] = {}
        
        # æ–‡å­—èµ·ã“ã—ã‚¨ãƒ³ã‚¸ãƒ³ã‚’é–‹å§‹
        self.transcription_engine.start()

        # çµæœãƒãƒ¼ãƒªãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
        if guild_id not in self.result_polling_tasks or self.result_polling_tasks[guild_id].done():
            self.result_polling_tasks[guild_id] = asyncio.create_task(
                self._result_polling_loop(guild_id)
            )

        # å®šæœŸçš„ãªãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹ (VADã«ä¾å­˜ã›ãšä¸€å®šé–“éš”ã§ãƒãƒ£ãƒ³ã‚¯ã‚’ç”Ÿæˆ)
        if guild_id not in self.periodic_chunk_processing_tasks or self.periodic_chunk_processing_tasks[guild_id].done():
            self.periodic_chunk_processing_tasks[guild_id] = asyncio.create_task(
                self._periodic_chunk_processing_loop(guild_id)
            )

        print(f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†ã‚’é–‹å§‹: Guild {guild_id}")
        
    def stop_processing(self, guild_id: int):
        """æŒ‡å®šã•ã‚ŒãŸã‚®ãƒ«ãƒ‰ã®éŸ³å£°å‡¦ç†ã‚’åœæ­¢"""
        if guild_id in self.result_polling_tasks:
            self.result_polling_tasks[guild_id].cancel()
            del self.result_polling_tasks[guild_id]

        if guild_id in self.periodic_chunk_processing_tasks:
            self.periodic_chunk_processing_tasks[guild_id].cancel()
            del self.periodic_chunk_processing_tasks[guild_id]
        
        # æ®‹ã‚Šã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã™ã¹ã¦å‡¦ç†ã—ã¦ã‹ã‚‰ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
        if guild_id in self.audio_buffers:
            for user_id, buffer in list(self.audio_buffers[guild_id].items()):
                remaining_audio = buffer.get_remaining_audio()
                if remaining_audio:
                    self.transcription_engine.submit_audio(remaining_audio, user_id, buffer.username, guild_id)
            del self.audio_buffers[guild_id]
            
        if guild_id in self.text_channels:
            del self.text_channels[guild_id]

        # æ–‡å­—èµ·ã“ã—ã‚¨ãƒ³ã‚¸ãƒ³ã¯å…¨ä½“ã§ä¸€ã¤ãªã®ã§ã€ãƒœãƒƒãƒˆåœæ­¢æ™‚ã®ã¿æ­¢ã‚ã‚‹
        # self.transcription_engine.stop() # ã“ã‚Œã¯Botçµ‚äº†æ™‚ã«è¡Œã†

        print(f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†ã‚’åœæ­¢: Guild {guild_id}")
        
    def process_audio(self, guild_id: int, user_id: int, username: str, audio_data: bytes):
        """OptimizedAudioSink ã‹ã‚‰å—ä¿¡ã—ãŸç”Ÿã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†"""
        if guild_id not in self.audio_buffers:
            return # å‡¦ç†ãŒé–‹å§‹ã•ã‚Œã¦ã„ãªã„ã‚®ãƒ«ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿ã¯ç„¡è¦–
        
        if user_id not in self.audio_buffers[guild_id]:
            self.audio_buffers[guild_id][user_id] = StreamingAudioBuffer(user_id, username)
        
        buffer = self.audio_buffers[guild_id][user_id]
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ ã—ã€VADã§ç™ºè©±çµ‚äº†ã‚’æ¤œå‡º
        speech_ended = buffer.add_audio(audio_data)
        
        # VADãŒç™ºè©±çµ‚äº†ã‚’æ¤œå‡ºã—ãŸå ´åˆã€æ®‹ã‚Šã®ãƒ‡ãƒ¼ã‚¿ã‚’æ–‡å­—èµ·ã“ã—ã‚¨ãƒ³ã‚¸ãƒ³ã«é€ä¿¡
        if speech_ended:
            remaining = buffer.get_remaining_audio()
            if remaining and len(remaining) > 0:
                print(f"DEBUG Processor: Speech ended detected for {username}. Submitting remaining {len(remaining)} bytes.")
                self.transcription_engine.submit_audio(remaining, user_id, username, guild_id)
            else:
                print(f"DEBUG Processor: Speech ended for {username}, but no remaining audio to process.")
        
    async def _periodic_chunk_processing_loop(self, guild_id: int):
        """å®šæœŸçš„ã«éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€ãƒãƒ£ãƒ³ã‚¯ã‚’ç”Ÿæˆã—ã¦æ–‡å­—èµ·ã“ã—ã‚¨ãƒ³ã‚¸ãƒ³ã«é€ä¿¡ã™ã‚‹ãƒ«ãƒ¼ãƒ—"""
        while True:
            await asyncio.sleep(REALTIME_CHUNK_DURATION_MS / 1000.0) # è¨­å®šã•ã‚ŒãŸé–“éš”ã§ãƒã‚§ãƒƒã‚¯

            if guild_id not in self.audio_buffers:
                break # ã‚®ãƒ«ãƒ‰ã®å‡¦ç†ãŒåœæ­¢ã•ã‚ŒãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹

            # Iterate over a copy of items to allow modification during iteration
            for user_id, buffer in list(self.audio_buffers[guild_id].items()):
                # `get_audio_chunk` ãŒå†…éƒ¨ã§é©åˆ‡ãªã‚µã‚¤ã‚ºã®ãƒãƒ£ãƒ³ã‚¯ã‚’ç®¡ç†
                chunk = buffer.get_audio_chunk()
                if chunk:
                    print(f"DEBUG Processor: Periodic chunk generated for {buffer.username} ({len(chunk)} bytes). Submitting.")
                    self.transcription_engine.submit_audio(chunk, user_id, buffer.username, guild_id)
                # ç™ºè©±çµ‚äº†æ™‚ã®å‡¦ç†ã¯process_audioã«ä»»ã›ã‚‹ãŸã‚ã€ã“ã®elifãƒ–ãƒ­ãƒƒã‚¯ã¯ä¸è¦
                    
    async def _result_polling_loop(self, guild_id: int):
        """æ–‡å­—èµ·ã“ã—çµæœã‚­ãƒ¥ãƒ¼ã‚’å®šæœŸçš„ã«ãƒãƒ¼ãƒªãƒ³ã‚°ã—ã€Discordã«é€ä¿¡ã™ã‚‹ãƒ«ãƒ¼ãƒ—"""
        while True:
            try:
                result = self.transcription_engine.get_result()
                if result and result['guild_id'] == guild_id:
                    text_channel = self.text_channels.get(guild_id)
                    if text_channel:
                        await text_channel.send(f"**{result['username']}**: {result['transcription']}")
                        print(f"æ–‡å­—èµ·ã“ã—é€ä¿¡: {result['username']} -> {result['transcription']}")
                
                await asyncio.sleep(0.05)  # 50msã”ã¨ã«ãƒã‚§ãƒƒã‚¯ (ãƒãƒ¼ãƒªãƒ³ã‚°é–“éš”)
            except asyncio.CancelledError:
                print(f"çµæœãƒãƒ¼ãƒªãƒ³ã‚°ãƒ«ãƒ¼ãƒ—ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ: Guild {guild_id}")
                break
            except Exception as e:
                print(f"ERROR: çµæœãƒãƒ¼ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ãƒ«ãƒ¼ãƒ—ã‚’ç¶šè¡Œã™ã‚‹ãŒã€è‡´å‘½çš„ãªå ´åˆã¯breakã™ã‚‹ã“ã¨ã‚‚æ¤œè¨
                await asyncio.sleep(1) # ã‚¨ãƒ©ãƒ¼æ™‚ã®é€£ç¶šãƒãƒ¼ãƒªãƒ³ã‚°ã‚’é˜²ã


# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° (Botèµ·å‹•æ™‚ã«åˆæœŸåŒ–ã•ã‚Œã‚‹)
transcription_engine: Optional[RealtimeTranscriptionEngine] = None
voice_processor: Optional[RealtimeVoiceProcessor] = None


class OptimizedAudioSink(AudioSink):
    """discord-ext-voice-recv ã‹ã‚‰ãƒ‡ã‚³ãƒ¼ãƒ‰æ¸ˆã¿PCMéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ä¿¡ã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ ã‚·ãƒ³ã‚¯"""
    
    def __init__(self, processor: RealtimeVoiceProcessor, guild_id: int):
        super().__init__()
        self.processor = processor
        self.guild_id = guild_id
        
    def write(self, user: discord.Member, data: VoiceData):
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ä¿¡ã—ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã«æ¸¡ã™"""
        if user.bot:
            return
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã«é€ä¿¡
        # data.pcm ã¯æ—¢ã«ãƒ‡ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸPCMãƒ‡ãƒ¼ã‚¿
        if self.processor: # ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            self.processor.process_audio(
                self.guild_id, 
                user.id, 
                user.display_name, 
                data.pcm
            )
            # StreamingAudioBuffer ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã® accumulated_audio ã®é•·ã•ã‚’å‚ç…§
            current_user_buffer = self.processor.audio_buffers.get(self.guild_id, {}).get(user.id)
            buffer_len = len(current_user_buffer.accumulated_audio) if current_user_buffer else 0
            print(f"DEBUG OptimizedAudioSink: User {user.display_name} received {len(data.pcm)} bytes. Total in buffer: {buffer_len} bytes.")
        else:
            print("WARNING: RealtimeVoiceProcessor is not initialized.")
    
    def wants_opus(self) -> bool:
        """ã‚·ãƒ³ã‚¯ãŒOpuså½¢å¼ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å¸Œæœ›ã™ã‚‹ã‹ã©ã†ã‹ã‚’è¿”ã—ã¾ã™ã€‚Falseã®å ´åˆã€PCMã‚’å—ã‘å–ã‚Šã¾ã™ã€‚"""
        return False
        
    def cleanup(self):
        """ã‚·ãƒ³ã‚¯ãŒç ´æ£„ã•ã‚Œã‚‹éš›ã«å‘¼ã³å‡ºã•ã‚Œã‚‹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ¡ã‚½ãƒƒãƒ‰ã§ã™ã€‚"""
        print(f"DEBUG OptimizedAudioSink: cleanup called for Guild {self.guild_id}.")
        pass


# Botã‚³ãƒãƒ³ãƒ‰
@bot.command()
async def join(ctx):
    """ãƒœãƒƒãƒˆã‚’ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«æ¥ç¶šã—ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°éŒ²éŸ³ãƒ»è»¢å†™ã‚’é–‹å§‹"""
    if ctx.author.voice is None:
        await ctx.send("âŒ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«æ¥ç¶šã—ã¦ãã ã•ã„ã€‚")
        return

    voice_channel = ctx.author.voice.channel
    
    # æ—¢å­˜ã®æ¥ç¶šãŒã‚ã‚Œã°åˆ‡æ–­ã—ã€é–¢é€£ã™ã‚‹å‡¦ç†ã‚’åœæ­¢
    if ctx.guild.id in connections:
        old_vc = connections[ctx.guild.id]
        if old_vc.is_connected():
            print(f"æ—¢å­˜ã®ãƒœã‚¤ã‚¹æ¥ç¶šã‚’åˆ‡æ–­ã—ã¾ã™: Guild {ctx.guild.id}")
            # å¤ã„æ¥ç¶šã‹ã‚‰ã®listenã‚’åœæ­¢
            old_vc.stop_listening()
            await old_vc.disconnect()
            
            # å¤ã„ã‚®ãƒ«ãƒ‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã‚‚åœæ­¢
            if voice_processor:
                voice_processor.stop_processing(ctx.guild.id)
            
            del connections[ctx.guild.id]
            await asyncio.sleep(0.5) # åˆ‡æ–­å‡¦ç†ãŒå®Œå…¨ã«çµ‚ã‚ã‚‹ã®ã‚’å¾…ã¤

    # VoiceRecvClient ã‚’ä½¿ç”¨ã—ã¦æ¥ç¶š
    try:
        vc = await voice_channel.connect(cls=VoiceRecvClient, reconnect=True) 
        connections[ctx.guild.id] = vc

        if voice_processor is None:
            await ctx.send("âŒ STTã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Botãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            print("ERROR: voice_processor is None. Cannot start processing.")
            return

        # éŸ³å£°ã‚·ãƒ³ã‚¯ã‚’è¨­å®šã—ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã‚’é–‹å§‹
        vc.listen(OptimizedAudioSink(voice_processor, ctx.guild.id))
        voice_processor.start_processing(ctx.guild.id, ctx.channel)
        
        print(f"ğŸ”Š VoiceRecvClient listening with OptimizedAudioSink for Guild {ctx.guild.id}.")

        await ctx.send(f'ğŸµ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ« **{voice_channel.name}** ã«æ¥ç¶šã—ã¾ã—ãŸï¼')
        await ctx.send(
            f"ğŸ™ï¸ **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼**\n"
            f"âš¡ å‡¦ç†é–“éš”: {REALTIME_CHUNK_DURATION_MS}ms\n"
            f"ğŸ¯ VADæ„Ÿåº¦: {VAD_AGGRESSIVENESS}/3\n"
            f"ğŸ”Š éŸ³å£°æ¤œå‡ºé–¾å€¤: {SILENCE_THRESHOLD_MS}ms\n"
            f"â„¹ï¸ `!leave` ã§æ¥ç¶šã‚’åˆ‡æ–­ã§ãã¾ã™ã€‚"
        )
        print("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ç›£è¦–é–‹å§‹ã€‚")

    except discord.errors.ClientException as e:
        await ctx.send(f"âŒ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        print(f"ERROR: Failed to connect to voice channel: {e}")
    except Exception as e:
        await ctx.send(f"âŒ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print(f"ERROR: An unexpected error occurred in !join: {e}")


@bot.command()
async def leave(ctx):
    """ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰åˆ‡æ–­ã—ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°éŒ²éŸ³ã‚’åœæ­¢"""
    if ctx.guild.id not in connections:
        await ctx.send("âŒ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«æ¥ç¶šã—ã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    vc = connections[ctx.guild.id]
    
    await ctx.send("ğŸ›‘ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ç›£è¦–ã‚’åœæ­¢ã—ã¦ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰åˆ‡æ–­ã—ã¾ã™...")

    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã‚’åœæ­¢ï¼ˆã“ã‚Œã«ã‚ˆã‚Šãƒãƒƒãƒ•ã‚¡ã®æ®‹ã‚ŠãŒå‡¦ç†ã•ã‚Œã‚‹ï¼‰
    if voice_processor:
        voice_processor.stop_processing(ctx.guild.id)

    # VoiceRecvClient ã® listen ã‚’åœæ­¢ã—ã€åˆ‡æ–­
    vc.stop_listening() # æ˜ç¤ºçš„ã«ãƒªã‚¹ãƒŠãƒ¼ã‚’åœæ­¢
    await vc.disconnect()
    del connections[ctx.guild.id]
    
    await ctx.send("ğŸ‘‹ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰åˆ‡æ–­ã—ã¾ã—ãŸã€‚")
    print('BotãŒãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰åˆ‡æ–­ã—ã¾ã—ãŸã€‚')


@bot.command()
async def status(ctx):
    """ç¾åœ¨ã®çŠ¶æ³ã‚’ç¢ºèª"""
    if ctx.guild.id not in connections:
        await ctx.send("âŒ ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«æ¥ç¶šã—ã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    vc = connections[ctx.guild.id]
    channel_members = len(vc.channel.members) - 1 # Botè‡ªèº«ã‚’é™¤ã
    
    status_msg = f"ğŸ“Š **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ç¨¼åƒä¸­**\n"
    status_msg += f"ğŸ¤ ãƒãƒ£ãƒ³ãƒãƒ«å‚åŠ è€…: {channel_members}äºº\n"
    status_msg += f"âš¡ å‡¦ç†é–“éš”: {REALTIME_CHUNK_DURATION_MS}ms\n"
    status_msg += f"ğŸ¯ VADæ„Ÿåº¦: {VAD_AGGRESSIVENESS}/3\n"
    status_msg += f"ğŸ”Š éŸ³å£°æ¤œå‡ºé–¾å€¤: {SILENCE_THRESHOLD_MS}ms\n"
    
    # ç¾åœ¨ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®é‡ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    if ctx.guild.id in voice_processor.audio_buffers:
        for user_id, buffer in voice_processor.audio_buffers[ctx.guild.id].items():
            user = bot.get_user(user_id) or ctx.guild.get_member(user_id)
            if user:
                status_msg += f"Buffer ({user.display_name}): {len(buffer.accumulated_audio)} bytes\n"
    
    await ctx.send(status_msg)

@bot.command()
async def toggle_debug_audio(ctx):
    """ãƒ‡ãƒãƒƒã‚°ç”¨éŸ³å£°ä¿å­˜ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚"""
    global SAVE_DEBUG_AUDIO
    SAVE_DEBUG_AUDIO = not SAVE_DEBUG_AUDIO
    status_text = "æœ‰åŠ¹" if SAVE_DEBUG_AUDIO else "ç„¡åŠ¹"
    await ctx.send(f"ğŸ”Š ãƒ‡ãƒãƒƒã‚°ç”¨éŸ³å£°ä¿å­˜ã‚’**{status_text}**ã«ã—ã¾ã—ãŸã€‚\nä¿å­˜å…ˆ: `{DEBUG_AUDIO_SAVE_DIR}`")


@bot.event
async def on_ready():
    """Botèµ·å‹•æ™‚ã®åˆæœŸåŒ–"""
    print(f'{bot.user} ãŒDiscordã«æ¥ç¶šã—ã¾ã—ãŸï¼')
    
    global WHISPER_MODEL, transcription_engine, voice_processor
    try:
        print(f"Whisperãƒ¢ãƒ‡ãƒ« ({WHISPER_MODEL_SIZE}, {WHISPER_DEVICE}, {WHISPER_COMPUTE_TYPE}) ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        WHISPER_MODEL = WhisperModel(WHISPER_MODEL_SIZE, device=WHISPER_DEVICE, compute_type=WHISPER_COMPUTE_TYPE)
        print("âœ… Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        
        # ã‚¨ãƒ³ã‚¸ãƒ³ã¨ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã‚’åˆæœŸåŒ–
        transcription_engine = RealtimeTranscriptionEngine(WHISPER_MODEL, AUDIO_OUTPUT_DIR)
        voice_processor = RealtimeVoiceProcessor(transcription_engine)
        
        print("âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"âŒ Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        WHISPER_MODEL = None

    print(f'åˆ©ç”¨å¯èƒ½ãªSTT: {"âœ… ãƒ­ãƒ¼ã‚«ãƒ«Whisper" if WHISPER_MODEL else "âŒ ãªã—"}')

@bot.event
async def on_voice_state_update(member, before, after):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«çŠ¶æ…‹æ›´æ–°ã‚¤ãƒ™ãƒ³ãƒˆ"""
    # ã“ã®ã‚¤ãƒ™ãƒ³ãƒˆã¯ãƒœãƒƒãƒˆã®æ¥ç¶šçŠ¶æ…‹ã‚„ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒŸãƒ¥ãƒ¼ãƒˆãƒ»ãƒ‡ãƒ•ã«ãªã£ãŸã‚Šã€ãƒãƒ£ãƒ³ãƒãƒ«ã‚’ç§»å‹•ã—ãŸã‚Šã—ãŸã¨ãã«ç™ºç”Ÿã—ã¾ã™ã€‚
    # ã“ã“ã§ã¯ä¸»ã«ãƒ‡ãƒãƒƒã‚°ç›®çš„ã§ä½¿ç”¨ã€‚
    if member == bot.user:
        return # Botè‡ªèº«ã®çŠ¶æ…‹å¤‰æ›´ã¯ç„¡è¦–

    guild_id = member.guild.id
    # BotãŒæ¥ç¶šã—ã¦ã„ã‚‹ã‚®ãƒ«ãƒ‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®çŠ¶æ…‹å¤‰æ›´ã®ã¿ã‚’å‡¦ç†
    if guild_id in connections and connections[guild_id].is_connected():
        # ãƒãƒ£ãƒ³ãƒãƒ«ã®ç§»å‹•ã‚„é€€å‡º
        if before.channel and before.channel != after.channel:
            print(f'DEBUG on_voice_state_update: {member.display_name} ãŒ {before.channel.name} ã‹ã‚‰é€€å‡ºã—ã¾ã—ãŸã€‚')
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã‚’é€€å‡ºã—ãŸå ´åˆã€ãã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ®‹ã‚Šã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
            if voice_processor and guild_id in voice_processor.audio_buffers and member.id in voice_processor.audio_buffers[guild_id]:
                text_channel = voice_processor.text_channels.get(guild_id)
                if text_channel:
                    buffer = voice_processor.audio_buffers[guild_id].pop(member.id)
                    remaining_audio = buffer.get_remaining_audio()
                    if remaining_audio:
                        print(f"DEBUG on_voice_state_update: {member.display_name} ã®é€€å‡ºã‚’æ¤œçŸ¥ã€‚æ®‹ã‚Šã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ {len(remaining_audio)} ãƒã‚¤ãƒˆã‚’å‡¦ç†ã—ã¾ã™ã€‚")
                        voice_processor.transcription_engine.submit_audio(remaining_audio, member.id, member.display_name, guild_id)
                    else:
                        print(f"DEBUG on_voice_state_update: {member.display_name} ã®é€€å‡ºã‚’æ¤œçŸ¥ã—ã¾ã—ãŸãŒã€æœªå‡¦ç†ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    print(f"WARNING: ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ãƒãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€{member.display_name} ã®æ®‹ã‚Šã®éŸ³å£°ã‚’å‡¦ç†ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")


# Botã®å®Ÿè¡Œ
if DISCORD_BOT_TOKEN:
    try:
        bot.run(DISCORD_BOT_TOKEN)
    except Exception as e:
        print(f"Botã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    finally:
        # ãƒœãƒƒãƒˆãŒã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ã™ã‚‹éš›ã«æ–‡å­—èµ·ã“ã—ã‚¨ãƒ³ã‚¸ãƒ³ã‚‚åœæ­¢
        if transcription_engine:
            transcription_engine.stop()
else:
    print("ã‚¨ãƒ©ãƒ¼: Discord Botãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚'.env'ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

